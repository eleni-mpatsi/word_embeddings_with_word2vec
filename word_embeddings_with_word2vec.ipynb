{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from bs4 import BeautifulSoup\n",
        "\n",
        "imdb_dataset_path = 'IMDB Dataset.csv'\n",
        "\n",
        "# read the data from csv file to a dataframe\n",
        "imdb_data = pd.read_csv(imdb_dataset_path, delimiter=',', quotechar='\"')\n",
        "imdb_data = imdb_data.dropna().reset_index(drop=True)\n",
        "\n",
        "# extract the \"review\" column\n",
        "reviews = imdb_data['review']\n",
        "\n",
        "def cleaned_data(review):\n",
        "    if pd.notna(review):\n",
        "        # remove html tags\n",
        "        review = BeautifulSoup(review, 'html.parser').get_text()\n",
        "        # remove punctuation - convert to lowercase\n",
        "        review = re.sub(r'[^a-zA-Z\\s]', '', review).strip().lower()\n",
        "        return review\n",
        "    else:\n",
        "        return ''\n",
        "\n",
        "# apply the function to each review\n",
        "cleaned_reviews = reviews.apply(cleaned_data)\n",
        "\n",
        "#remove duplicates\n",
        "cleaned_reviews = cleaned_reviews.dropna().drop_duplicates()\n",
        "\n",
        "#check the reviews with head command\n",
        "print(cleaned_reviews.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4CjNIwIy1oKj",
        "outputId": "176a56c5-edf4-4580-b74d-e07c485f1f5b"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-21ee1d362b1e>:18: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  review = BeautifulSoup(review, 'html.parser').get_text()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    one of the other reviewers has mentioned that ...\n",
            "1    a wonderful little production the filming tech...\n",
            "2    i thought this was a wonderful way to spend ti...\n",
            "3    basically theres a family where a little boy j...\n",
            "4    petter matteis love in the time of money is a ...\n",
            "Name: review, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import io\n",
        "\n",
        "print('Tokenizing reviews...')\n",
        "\n",
        "# Track the total number of tokens in the dataset.\n",
        "num_tokens = 0\n",
        "# empty list for reviews to train\n",
        "reviews = []\n",
        "\n",
        "# For each review...\n",
        "for i, review in enumerate(cleaned_reviews):\n",
        "    # Report progress.\n",
        "    if ((i % 20000) == 0):\n",
        "        print('  Read {:,} reviews.'.format(i))\n",
        "\n",
        "    # Tokenize the review. This returns a list of words.\n",
        "    parsed = gensim.utils.simple_preprocess(review)\n",
        "    # Accumulate the total number of words in the dataset.\n",
        "    num_tokens += len(parsed)\n",
        "    # Add the review to the list.\n",
        "    reviews.append(parsed)\n",
        "\n",
        "print('DONE.')\n",
        "print('')\n",
        "print('{:>10,} reviews'.format(i + 1))\n",
        "print('{:>10,} tokens'.format(num_tokens))\n",
        "print('{:>10,} avg. tokens / review'.format(int(num_tokens / len(reviews))))\n",
        "print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dw6nwkiO18J-",
        "outputId": "78eebb68-4b82-4926-c1b9-ceac67ada147"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizing reviews...\n",
            "  Read 0 reviews.\n",
            "  Read 20,000 reviews.\n",
            "  Read 40,000 reviews.\n",
            "DONE.\n",
            "\n",
            "    49,580 reviews\n",
            "10,683,902 tokens\n",
            "       215 avg. tokens / review\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "# Enable logging at the `INFO` level and set a custom format--the\n",
        "logging.basicConfig(\n",
        "    format='%(asctime)s : %(message)s', # Display just time and message.\n",
        "    datefmt='%H:%M:%S', # Display time, but not the date.\n",
        "    level=logging.INFO)"
      ],
      "metadata": {
        "id": "NyETy-Iv2PS_"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set the parameters\n",
        "model = gensim.models.Word2Vec(\n",
        "    vector_size=100,  # Number of features in word vector\n",
        "    window=5,        # Context window size (in each direction)\n",
        "    min_count=5,      # Words must appear this many times to be in vocab.\n",
        "    workers=3,       # Training thread count\n",
        "    sg=0,             # 0: CBOW, 1: Skip-gram. Default is 0, CBOW\n",
        "    hs=0,             # 0: Negative Sampling, 1: Hierarchical Softmax Default is 0, NS\n",
        "    negative=5        # Number of negative samples Default is 5\n",
        ")\n",
        "\n",
        "#build the vocabulary using the tokenized reviews\n",
        "model.build_vocab(reviews, progress_per=20000)\n",
        "\n",
        "print('Training the model...')\n",
        "\n",
        "#train the model\n",
        "model.train(\n",
        "    reviews,\n",
        "    total_examples=len(reviews),\n",
        "    epochs=10,        # How many training passes to take.\n",
        "    report_delay=10.0 # Report progress every 10 seconds.\n",
        ")\n"
      ],
      "metadata": {
        "id": "FfT8FBQ12QtI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef7fb6b3-6fd8-4ff2-bb42-2564bdda817f"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80342084, 106839020)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find 5 most similar words to a given word\n",
        "\n",
        "word = \"bed\"\n",
        "similar_words = model.wv.most_similar(word, topn=5)\n",
        "print(f\"Words similar to {word}: {similar_words}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8frQMSFc2Qzu",
        "outputId": "1e95c541-a4e5-43cc-e999-2ab5d839c85f"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words similar to bed: [('bedroom', 0.6440098285675049), ('bathtub', 0.6371393799781799), ('chair', 0.6043896675109863), ('sleeping', 0.6001318693161011), ('bathroom', 0.5994760394096375)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word1 ='intelligent'\n",
        "word2 = 'smart'\n",
        "\n",
        "# compute similarity between two words\n",
        "similarity_score = model.wv.similarity(word1 , word2)\n",
        "print(f\"Similarity between {word1} and {word2}: {similarity_score}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXeEHywv2Q23",
        "outputId": "945d5134-218d-4bd7-d29c-2a05bb39fbd7"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Similarity between intelligent and smart: 0.6015122532844543\n",
            "The word that does not match: beautiful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# find word that does not match in a list\n",
        "not_matching = model.wv.doesnt_match(['ugly', 'bad', 'beautiful', 'disappointing'])\n",
        "print(f\"The word that does not match: {not_matching}\")"
      ],
      "metadata": {
        "id": "qSnATZ3DnAo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# analogy difference\n",
        "\n",
        "analogy_result = model.wv.most_similar(positive=['good', 'bad'], negative=['better'], topn=5)\n",
        "print(f\"Analogy difference: {analogy_result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXGBjsZs2nYO",
        "outputId": "ab2a8929-b38e-4cca-98fe-e8ac46daf8db"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Analogy difference: [('badthe', 0.6677297353744507), ('lame', 0.6527222990989685), ('awful', 0.6282227039337158), ('stupid', 0.6139384508132935), ('cool', 0.6059989929199219)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TRAINING OF MODEL 2\n",
        "model_2 = gensim.models.Word2Vec(\n",
        "    vector_size=150,\n",
        "    window=10,\n",
        "    min_count=2,\n",
        "    workers=10,\n",
        "    sg=1,      #Skip-gram.\n",
        "    hs=1,       #Hierarchical Softmax\n",
        "    negative=10\n",
        ")"
      ],
      "metadata": {
        "id": "5mwdVJyr_o_S"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the vocabulary using the tokenized reviews\n",
        "model_2.build_vocab(reviews, progress_per=20000)\n",
        "\n",
        "print('Training the model...')\n",
        "\n",
        "model.train(\n",
        "    reviews,\n",
        "    total_examples=len(reviews),\n",
        "    epochs=10,        # How many training passes to take.\n",
        "    report_delay=10.0 # Report progress every 10 seconds.\n",
        ")\n",
        "\n",
        "print('  Done.')\n",
        "print('')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXRgx6F938gL",
        "outputId": "ffe3a650-71ca-439f-9676-43541580333e"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.word2vec:Effective 'alpha' higher than previous training cycles\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the model...\n",
            "  Done.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#EXPERIMENTS ON MODEL 2\n",
        "word = \"bed\"\n",
        "similar_words = model_2.wv.most_similar(word, topn=5)\n",
        "print(f\"Words similar to {word}: {similar_words}\")\n",
        "\n",
        "word1 ='intelligent'\n",
        "word2 = 'smart'\n",
        "\n",
        "similarity_score = model_2.wv.similarity(word1 , word2)\n",
        "print(f\"Similarity between {word1} and {word2}: {similarity_score}\")\n",
        "\n",
        "not_matching = model_2.wv.doesnt_match(['ugly', 'bad', 'beautiful', 'disappointing'])\n",
        "print(f\"The word that does not match: {not_matching}\")\n",
        "\n",
        "analogy_result = model_2.wv.most_similar(positive=['good', 'bad'], negative=['better'], topn=5)\n",
        "print(f\"Analogy difference: {analogy_result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbijFDN9_pCc",
        "outputId": "e0c86b4d-e711-438b-9a8c-4002c0ccd0d6"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words similar to bed: [('roleit', 0.35866743326187134), ('maths', 0.3582352101802826), ('lizzy', 0.33760711550712585), ('pilgers', 0.33652395009994507), ('stowes', 0.3319588005542755)]\n",
            "Similarity between intelligent and smart: 0.05478953570127487\n",
            "The word that does not match: disappointing\n",
            "Analogy difference: [('oneyear', 0.33537420630455017), ('motormouthed', 0.33413413166999817), ('mcfarlane', 0.33332687616348267), ('harlows', 0.3136191964149475), ('implore', 0.30584606528282166)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TRAINING OF MODEL 3\n",
        "model_3 = gensim.models.Word2Vec(\n",
        "    vector_size=200,\n",
        "    window=8,\n",
        "    min_count=10,\n",
        "    workers=5,\n",
        "    sg=1,    #  Skip-gram\n",
        "    hs=0,    # negative Sampling\n",
        "    negative=7\n",
        ")\n",
        "\n",
        "# Build the vocabulary using the tokenized reviews\n",
        "model_3.build_vocab(reviews, progress_per=20000)\n",
        "\n",
        "print('Training the third model...')\n",
        "model_3.train(\n",
        "    reviews,\n",
        "    total_examples=len(reviews),\n",
        "    epochs=15,        # Increase the number of training epochs for better convergence\n",
        "    report_delay=10.0 # Report progress every 10 seconds\n",
        ")\n",
        "print('  Done.')\n",
        "print('')\n"
      ],
      "metadata": {
        "id": "tx2Ptvjz_pSr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9ce99e5-05a1-4a35-f00c-4f9cb33e7251"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training the third model...\n",
            "  Done.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#EXPERIMENTS ON MODEL 3\n",
        "\n",
        "word = \"bed\"\n",
        "similar_words = model_3.wv.most_similar(word, topn=5)\n",
        "print(f\"Words similar to {word}: {similar_words}\")\n",
        "\n",
        "word1 ='intelligent'\n",
        "word2 = 'smart'\n",
        "similarity_score = model_3.wv.similarity(word1 , word2)\n",
        "print(f\"Similarity between {word1} and {word2}: {similarity_score}\")\n",
        "\n",
        "not_matching = model_3.wv.doesnt_match(['ugly', 'bad', 'beautiful', 'disappointing'])\n",
        "print(f\"The word that does not match: {not_matching}\")\n",
        "\n",
        "analogy_result = model_3.wv.most_similar(positive=['good', 'bad'], negative=['better'], topn=5)\n",
        "print(f\"Analogy difference: {analogy_result}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIF7hOQsl1vi",
        "outputId": "954e2f01-5e88-4a86-97c1-f47862adf9a2"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Words similar to bed: [('sleep', 0.5334925055503845), ('sleeping', 0.5220689177513123), ('curled', 0.5137509703636169), ('sofa', 0.501558780670166), ('trance', 0.49824783205986023)]\n",
            "Similarity between intelligent and smart: 0.5877595543861389\n",
            "The word that does not match: beautiful\n",
            "Analogy difference: [('awful', 0.5075327754020691), ('terrible', 0.5051887035369873), ('badthe', 0.47965189814567566), ('hilariousthe', 0.4481655955314636), ('cool', 0.4473189115524292)]\n"
          ]
        }
      ]
    }
  ]
}